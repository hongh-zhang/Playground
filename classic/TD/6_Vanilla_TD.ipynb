{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef39f537-d878-4883-802c-14497997c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb7e331-72ba-4067-ab17-1f51acc6e55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'S' b'F' b'F' b'F']\n",
      " [b'F' b'H' b'F' b'H']\n",
      " [b'F' b'F' b'F' b'H']\n",
      " [b'H' b'F' b'F' b'G']]\n"
     ]
    }
   ],
   "source": [
    "SIZE = 4  # map size\n",
    "\n",
    "env = gym.make('FrozenLake-v1', is_slippery=False)\n",
    "print(env.desc)\n",
    "\n",
    "def int2loc(x):\n",
    "    \"\"\"\n",
    "    Convert state number into 2d matrix index\n",
    "    e.g. 3 -> (0, 4),  4 -> (1, 0)\n",
    "    \"\"\"\n",
    "    return (x // SIZE, x % SIZE)\n",
    "\n",
    "assert int2loc(8) == (2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415a745-9caa-4405-a063-6047aed8d318",
   "metadata": {},
   "source": [
    "# SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0721f541-6d8e-4591-b40f-0d55addf2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARSA():\n",
    "    \n",
    "    def __init__(self, choice=[0,1,2,3], shape=(SIZE, SIZE, 4), e=0.8, y=0.9, lr=1e-1,):\n",
    "        \n",
    "        self.e  = e  # epsilon\n",
    "        self.y  = y  # gamma\n",
    "        self.lr = lr  # learning rate\n",
    "        self.q = np.random.randn(*shape)  # q value array\n",
    "        self.choice = choice  # action space\n",
    "        \n",
    "        self.test_mode = False\n",
    "    \n",
    "    def action(self, state):\n",
    "        \n",
    "        # exploration\n",
    "        if not self.test_mode and np.random.rand() <= self.e:\n",
    "            action = np.random.choice(self.choice)\n",
    "            \n",
    "        # greedy policy\n",
    "        else:\n",
    "            action = np.argmax(self.q[state])\n",
    "        return action\n",
    "    \n",
    "    def learn(self, state, action, state_, action_, reward, done):\n",
    "        \n",
    "        # (pseudocode on p130)\n",
    "        q_next = self.q[(*state_, action_)] if not done else 0.0\n",
    "        td_error = reward + self.y*q_next - self.q[(*state, action)]\n",
    "        self.q[(*state, action)] += self.lr * td_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ceb9b5e-e96c-4308-81cb-ae0dc1904a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode(env, agent):\n",
    "    \n",
    "    state = int2loc(env.reset())\n",
    "    action = agent.action(state)\n",
    "    \n",
    "    for step in range(MAX_STEPS):\n",
    "        \n",
    "        # take action & observe\n",
    "        state_, reward, done, _ = env.step(action)\n",
    "        state_ = int2loc(state_)\n",
    "        \n",
    "        # choose next action\n",
    "        action_ = agent.action(state_)\n",
    "        \n",
    "        # update q value\n",
    "        agent.learn(state, action, state_, action_, reward, done);\n",
    "        \n",
    "        # iter to next step\n",
    "        state = state_\n",
    "        action = action_\n",
    "        \n",
    "        if done:\n",
    "            return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb8343d9-6e78-40f3-adab-57a1540453a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPISODES = 10000\n",
    "MAX_STEPS = 100  # max steps before terminating an episode\n",
    "\n",
    "agent = SARSA(e=1, lr=0.2)\n",
    "steps = []\n",
    "\n",
    "for i in range(EPISODES):\n",
    "    \n",
    "    episode(env, agent);\n",
    "    \n",
    "    if agent.e >= 0.2:\n",
    "        agent.e *= 0.996\n",
    "        \n",
    "    if i % 20 == 0:\n",
    "        agent.test_mode = True\n",
    "        steps.append(episode(env, agent))\n",
    "        agent.test_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f5fa34f-f2b6-40a2-ad7a-9debada23924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learning curve\n",
    "plt.scatter(range(len(steps)), steps);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea70d6a6-4d6b-4ba9-9187-a7c3e2f0fa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['↓', '←', '←', '←'],\n",
       "       ['↓', 'H', '↓', 'H'],\n",
       "       ['→', '→', '↓', 'H'],\n",
       "       ['H', '→', '→', 'G']], dtype='<U1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize policy\n",
    "arrows = np.array(['←','↓','→','↑'])\n",
    "np.array([arrows[np.argmax(agent.q, axis=2)[i,j]] \n",
    "          if (env.desc[i,j] == env.desc[0,0]) or (env.desc[i,j] == env.desc[0,1]) else env.desc[i,j]\n",
    "          for i in range(4) for j in range(4)\n",
    "          ]).reshape(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a1f7f-707e-437d-a0cd-e3a6fe9fac76",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45dfe507-8f76-4161-9183-4c4c3104cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QL(SARSA):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def learn(self, state, action, state_, action_, reward, done):\n",
    "        \n",
    "        # (6.8 on p131)\n",
    "        q_next = np.max(self.q[state_]) if not done else 0.0         # <- difference\n",
    "        td_error = reward + self.y*q_next - self.q[(*state, action)]\n",
    "        self.q[(*state, action)] += self.lr * td_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f928082-1a62-44ef-9a19-da9c161c42c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 10000\n",
    "MAX_STEPS = 100\n",
    "\n",
    "agent = QL(e=1, lr=0.6)\n",
    "steps = []\n",
    "\n",
    "for i in range(EPISODES):\n",
    "    \n",
    "    episode(env, agent);\n",
    "    \n",
    "    if agent.e >= 0.2:\n",
    "        agent.e *= 0.996\n",
    "        \n",
    "    if i % 20 == 0:\n",
    "        agent.test_mode = True\n",
    "        steps.append(episode(env, agent))\n",
    "        agent.test_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b934a7b8-b9c6-424e-a8ad-fca0fae22b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(len(steps)), steps);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f577c8a-3d28-45a6-b746-419847878c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['↓', '←', '←', '←'],\n",
       "       ['↓', 'H', '↑', 'H'],\n",
       "       ['→', '↓', '↓', 'H'],\n",
       "       ['H', '→', '→', 'G']], dtype='<U1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([arrows[np.argmax(agent.q, axis=2)[i,j]] \n",
    "          if (env.desc[i,j] == env.desc[0,0]) or (env.desc[i,j] == env.desc[0,1]) else env.desc[i,j]\n",
    "          for i in range(4) for j in range(4)\n",
    "          ]).reshape(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e9bd7-8fa8-4d86-a176-a536ab8a317f",
   "metadata": {},
   "source": [
    "## Cliff Walking (Example 6.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da85c87b-b3eb-4ca8-88c5-c89a43ddaf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cliff environment\n",
    "class Cliff():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.map = np.ones((4,6)) * (-1)\n",
    "        self.map[0,5] = 0  # goal\n",
    "        self.map[0,1:5] = -100  # cliff\n",
    "        self.actions = [(0,-1),(1,0),(0,1),(-1,0)]\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.loc = (0,0)\n",
    "        return self.loc\n",
    "    \n",
    "    def step(self, action):\n",
    "        x, y = self.actions[action]\n",
    "        x = np.clip(self.loc[0] + x, 0, 3)\n",
    "        y = np.clip(self.loc[1] + y, 0, 5)\n",
    "        self.loc = (x, y)\n",
    "        reward = self.map[self.loc]\n",
    "        return self.loc, reward, reward!=(-1), None  # to be consistent withh gym's return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35a56ca7-2762-4cc8-a45b-6c957da3a0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -1. -100. -100. -100. -100.    0.]\n",
      " [  -1.   -1.   -1.   -1.   -1.   -1.]\n",
      " [  -1.   -1.   -1.   -1.   -1.   -1.]\n",
      " [  -1.   -1.   -1.   -1.   -1.   -1.]]\n"
     ]
    }
   ],
   "source": [
    "# payoff map\n",
    "env = Cliff()\n",
    "print(env.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51e0aa1f-60a4-4a5f-99a2-df8c1416a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode function without int2loc\n",
    "def episode2(env, agent):\n",
    "    \n",
    "    state = env.reset()\n",
    "    action = agent.action(state)\n",
    "    \n",
    "    for step in range(MAX_STEPS):\n",
    "        \n",
    "        # take action & observe\n",
    "        state_, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # choose next action\n",
    "        action_ = agent.action(state_)\n",
    "        \n",
    "        # update q value\n",
    "        agent.learn(state, action, state_, action_, reward, done);\n",
    "        \n",
    "        # iter to next step\n",
    "        state = state_\n",
    "        action = action_\n",
    "        \n",
    "        if done:\n",
    "            return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82a55ced-20ab-4688-a81d-5d18cf5e2887",
   "metadata": {},
   "outputs": [],
   "source": [
    "ql    = QL(e=0.1, shape=(4,6,4))\n",
    "sarsa = SARSA(e=0.1, shape=(4,6,4))\n",
    "\n",
    "for _ in range(10000):\n",
    "    episode2(env, ql)\n",
    "    episode2(env, sarsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "457a8556-8854-40e2-9db9-975b692d8361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['↓', '-100.0', '-100.0', '-100.0', '-100.0', '0.0'],\n",
       "       ['→', '→', '→', '→', '→', '↑'],\n",
       "       ['↑', '↑', '→', '↑', '→', '↑'],\n",
       "       ['↓', '↑', '→', '→', '→', '↑']], dtype='<U32')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q learning policy\n",
    "# (optimal, shortest)\n",
    "np.array([arrows[np.argmax(ql.q, axis=2)[i,j]]\n",
    "          if env.map[i,j]==-1 else env.map[i,j]\n",
    "          for i in range(4) for j in range(6)\n",
    "          ]).reshape(4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d38a6be2-8b5d-485e-bb02-937d8947baa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['↓', '-100.0', '-100.0', '-100.0', '-100.0', '0.0'],\n",
       "       ['↓', '↓', '↓', '↓', '→', '↑'],\n",
       "       ['→', '↓', '→', '↓', '→', '↑'],\n",
       "       ['→', '→', '→', '→', '→', '↑']], dtype='<U32')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sarsa policy\n",
    "# (safest under epsilon-greedy)\n",
    "np.array([arrows[np.argmax(sarsa.q, axis=2)[i,j]]\n",
    "          if env.map[i,j]==-1 else env.map[i,j]\n",
    "          for i in range(4) for j in range(6)\n",
    "          ]).reshape(4,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a1eb14-32c3-423a-8aab-a432b4b20bcb",
   "metadata": {},
   "source": [
    "# Expected Sarsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25766199-7ff8-4f8d-a160-2cfbcf01a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QL(SARSA):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def learn(self, state, action, state_, action_, reward, done):\n",
    "        \n",
    "        # (6.9 on p133)\n",
    "        pi_next = np.ones(len(self.choice)) * self.e / len(self.choice)\n",
    "        pi_next[np.argmax(self.q[state_])] = 1 - self.e * (len(self.choice)-1) / len(self.choice)\n",
    "        q_next = np.sum(pi_next * self.q[state_]) if not done else 0.0\n",
    "        \n",
    "        td_error = reward + self.y*q_next - self.q[(*state, action)]\n",
    "        \n",
    "        self.q[(*state, action)] += self.lr * td_error\n",
    "        \n",
    "    def generate_policy(self):\n",
    "        self.policy = np.argmax(self.q, axis=2)\n",
    "        np.ones(self.shape) * self.e / len(self.choice)\n",
    "\n",
    "# (NOT TESTED YET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a48829-f6b2-4888-a57f-4b3fbb850c59",
   "metadata": {},
   "source": [
    "# Double Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80fa7c5b-bd16-4617-9064-6987e67b0f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQL():\n",
    "        \n",
    "    def __init__(self, choice=[0,1,2,3], shape=(SIZE, SIZE, 4), e=0.8, y=0.9, lr=1e-1,):\n",
    "        \n",
    "        self.e  = e\n",
    "        self.y  = y\n",
    "        self.lr = lr\n",
    "        self.choice = choice\n",
    "        self.q1 = np.random.randn(*shape)\n",
    "        self.q2 = np.random.randn(*shape)\n",
    "        \n",
    "        self.test_mode = False\n",
    "    \n",
    "    def action(self, state):\n",
    "        if not self.test_mode and np.random.rand() <= self.e:\n",
    "            action = np.random.choice((self.choice))\n",
    "        else:\n",
    "            action = np.argmax(self.q1[state] + self.q2[state])\n",
    "        return action\n",
    "    \n",
    "    def learn(self, state, action, state_, action_, reward, done):\n",
    "        \n",
    "        # (p136)\n",
    "        if np.random.rand() <= 0.5:\n",
    "            q_next = self.q2[(*state_, np.argmax(self.q1[state_]))] if not done else 0.0\n",
    "            td_error = reward + self.y*q_next - self.q1[(*state, action)]\n",
    "            self.q1[(*state, action)] += self.lr * td_error\n",
    "        \n",
    "        else:\n",
    "            q_next = self.q1[(*state_, np.argmax(self.q2[state_]))] if not done else 0.0\n",
    "            td_error = reward + self.y*q_next - self.q2[(*state, action)]\n",
    "            self.q2[(*state, action)] += self.lr * td_error\n",
    "            \n",
    "    def generate_policy(self):\n",
    "        self.policy = np.argmax(self.q1 + self.q2, axis=2)\n",
    "        return self.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a123ebe-808d-4c7f-8955-6b7694cb0d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 10000\n",
    "MAX_STEPS = 100\n",
    "\n",
    "env = gym.make('FrozenLake-v1', is_slippery=False)\n",
    "agent = DQL(e=1, lr=1)\n",
    "steps = []\n",
    "\n",
    "for i in range(EPISODES):\n",
    "    \n",
    "    episode(env, agent);\n",
    "    \n",
    "    if agent.e >= 0.2:\n",
    "        agent.e *= 0.996\n",
    "        \n",
    "    if i % 20 == 0:\n",
    "        agent.test_mode = True\n",
    "        steps.append(episode(env, agent))\n",
    "        agent.test_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3cb11b5-f0d0-4c8a-8f53-d27beb8089c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(len(steps)), steps);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98e5277a-a340-4e02-a902-44d1fcc88140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['↓', '←', '←', '↓'],\n",
       "       ['↓', 'H', '↓', 'H'],\n",
       "       ['→', '↓', '↓', 'H'],\n",
       "       ['H', '→', '→', 'G']], dtype='<U1')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([arrows[agent.generate_policy()[i,j]] \n",
    "          if (env.desc[i,j] == env.desc[0,0]) or (env.desc[i,j] == env.desc[0,1]) else env.desc[i,j]\n",
    "          for i in range(4) for j in range(4)\n",
    "          ]).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8b81615-1c53-44b4-a504-f12cae86ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement maximization bias example (p134)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
