{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c674481f-a378-4091-80f0-470a3d29f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb3131c-69f7-4d3a-9408-e78f378d62cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'S' b'F' b'F' b'F']\n",
      " [b'F' b'H' b'F' b'H']\n",
      " [b'F' b'F' b'F' b'H']\n",
      " [b'H' b'F' b'F' b'G']]\n"
     ]
    }
   ],
   "source": [
    "SIZE = 4  # map size\n",
    "\n",
    "env = gym.make('FrozenLake-v1', is_slippery=False)\n",
    "print(env.desc)\n",
    "\n",
    "def int2loc(x):\n",
    "    \"\"\"\n",
    "    Convert state number into 2d matrix index\n",
    "    e.g. 3 -> (0, 4),  4 -> (1, 0)\n",
    "    \"\"\"\n",
    "    return (x // SIZE, x % SIZE)\n",
    "\n",
    "assert int2loc(8) == (2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cdaa92-35bb-4df6-b939-cf2eb055710e",
   "metadata": {},
   "source": [
    "# n-step Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472b3dd-d203-42ba-8f02-ae91d316c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *not to be confused with Q(sigma) described in the book\n",
    "# this is actually an alternative to n-step SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b56e5f-594c-467e-bf5a-a7398c8c5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode(env, agent, test=False):\n",
    "    \n",
    "    agent.test_mode = test\n",
    "    state = int2loc(env.reset())\n",
    "    \n",
    "    for step in range(MAX_STEPS):\n",
    "        \n",
    "        # choose next action\n",
    "        action = agent.action(state)\n",
    "        \n",
    "        # take action & observe\n",
    "        state_, reward, done, _ = env.step(action)\n",
    "        state_ = int2loc(state_)\n",
    "        agent.observe(reward, state_, done);\n",
    "\n",
    "        if done:\n",
    "            return reward\n",
    "        \n",
    "        # iter to next step\n",
    "        state = state_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "307f44c6-f483-43dc-85d0-69c64bb024d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_returns(rewards, gamma):\n",
    "    \"\"\"Discounted cumulative return on a given reward sequence\"\"\"\n",
    "    return sum([(gamma ** i) * rewards[i] for i in range(len(rewards))])\n",
    "    \n",
    "class NQL():\n",
    "    \n",
    "    def __init__(self, n=3, choice=[0,1,2,3], shape=(SIZE, SIZE, 4), e=0.8, y=0.9, lr=1e-1,):\n",
    "        \n",
    "        self.n  = n\n",
    "        self.state_actions = deque(maxlen=n)\n",
    "        self.rewards = deque(maxlen=n)\n",
    "        \n",
    "        self.e  = e  # epsilon\n",
    "        self.y  = y  # gamma\n",
    "        self.lr = lr  # learning rate\n",
    "        self.q = np.random.randn(*shape)  # q value array\n",
    "        self.choice = choice  # action space\n",
    "        \n",
    "        self.test_mode = False\n",
    "    \n",
    "    def action(self, state):\n",
    "        if not self.test_mode and np.random.rand() <= self.e:\n",
    "            action = np.random.choice(self.choice)\n",
    "        else:\n",
    "            action = np.argmax(self.q[state])\n",
    "        self.state_actions.append((*state, action))\n",
    "        return action\n",
    "    \n",
    "    def observe(self, reward, state_, done):\n",
    "        self.rewards.append(reward)\n",
    "        \n",
    "        # start learning once enough steps are simulated\n",
    "        if len(self.rewards) == self.n:\n",
    "            self.learn(state_, done)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state_actions = deque(maxlen=self.n)\n",
    "        self.rewards = deque(maxlen=self.n)\n",
    "    \n",
    "    def learn(self, state_, done):\n",
    "        \n",
    "        if not done:\n",
    "            # update according to t:t+n rewards\n",
    "            idx = self.state_actions[0]  # index for (state, action)\n",
    "            g = cum_returns(self.rewards, self.y) + (self.y ** self.n) * np.max(self.q[state_])\n",
    "            self.q[idx] += self.lr * (g - self.q[idx])\n",
    "        \n",
    "        else:\n",
    "            # update with n-1, n-2, ... steps\n",
    "            for i in range(self.n):\n",
    "                idx = self.state_actions[i]\n",
    "                g = cum_returns(list(self.rewards)[i:], self.y) + 0.0\n",
    "                self.q[idx] += self.lr * (g - self.q[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4187805-736d-4a48-ae25-9f297df9baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 1000\n",
    "MAX_STEPS = 100  # max steps before terminating an episode\n",
    "\n",
    "agents = [NQL(n=5, e=0.4, lr=0.2) for _ in range(5)]\n",
    "rewards = []\n",
    "\n",
    "for i in range(EPISODES):\n",
    "    \n",
    "    [episode(env, agt) for agt in agents];\n",
    "        \n",
    "    if i % 20 == 0:\n",
    "        r = [episode(env, agt, test=True) for agt in agents]\n",
    "        rewards.append(sum(r) / len(r))\n",
    "        \n",
    "    [agt.reset() for agt in agents];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c38172d6-5ad2-49c6-8c00-f00cc3609dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(len(rewards)), rewards);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9988d5a-eaab-41df-bb27-889052309f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['→', '→', '↓', '←'],\n",
       "       ['↑', 'H', '↓', 'H'],\n",
       "       ['↓', '→', '↓', 'H'],\n",
       "       ['H', '→', '→', 'G']], dtype='<U1')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrows = np.array(['←','↓','→','↑'])\n",
    "np.array([arrows[np.argmax(agents[0].q, axis=2)[i,j]] \n",
    "          if (env.desc[i,j] == env.desc[0,0]) or (env.desc[i,j] == env.desc[0,1]) else env.desc[i,j]\n",
    "          for i in range(4) for j in range(4)\n",
    "          ]).reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d501554-cd0c-4ac6-83fa-8a85dd385221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# implement off-policy n-step methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
